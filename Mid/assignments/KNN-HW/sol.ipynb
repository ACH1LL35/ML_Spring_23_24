{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'D:\\\\9th semester\\\\git\\\\ML_Spring_23_24\\\\Mid\\x07ssignments\\\\KNN-HW\\\\cifar-10-batches-py\\\\data_batch_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m cifar10_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m9th semester\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgit\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mML_Spring_23_24\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMid\u001b[39m\u001b[38;5;130;01m\\a\u001b[39;00m\u001b[38;5;124mssignments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mKNN-HW\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcifar-10-batches-py\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Load training and testing data from CIFAR10 dataset\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m data_utils\u001b[38;5;241m.\u001b[39mload_CIFAR10(cifar10_dir)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Checking the size of the training and testing data\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining data shape: \u001b[39m\u001b[38;5;124m'\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32md:\\9th semester\\git\\ML_Spring_23_24\\Mid\\assignments\\KNN-HW\\data_utils.py:31\u001b[0m, in \u001b[0;36mload_CIFAR10\u001b[1;34m(ROOT)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m     30\u001b[0m   f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_batch_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (b, ))\n\u001b[1;32m---> 31\u001b[0m   X, Y \u001b[38;5;241m=\u001b[39m load_CIFAR_batch(f)\n\u001b[0;32m     32\u001b[0m   xs\u001b[38;5;241m.\u001b[39mappend(X)\n\u001b[0;32m     33\u001b[0m   ys\u001b[38;5;241m.\u001b[39mappend(Y)    \n",
      "File \u001b[1;32md:\\9th semester\\git\\ML_Spring_23_24\\Mid\\assignments\\KNN-HW\\data_utils.py:17\u001b[0m, in \u001b[0;36mload_CIFAR_batch\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_CIFAR_batch\u001b[39m(filename):\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\" load single batch of cifar \"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     18\u001b[0m     datadict \u001b[38;5;241m=\u001b[39m load_pickle(f)\n\u001b[0;32m     19\u001b[0m     X \u001b[38;5;241m=\u001b[39m datadict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'D:\\\\9th semester\\\\git\\\\ML_Spring_23_24\\\\Mid\\x07ssignments\\\\KNN-HW\\\\cifar-10-batches-py\\\\data_batch_1'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, r'D:\\9th semester\\git\\ML_Spring_23_24\\Mid\\assignments\\KNN-HW')  # Insert the path to the directory containing data_utils.py\n",
    "import data_utils\n",
    "import download\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_data():\n",
    "    pass\n",
    "\n",
    "# Class to initialize and apply K-nearest neighbour classifier\n",
    "class KNearestNeighbor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # Method to initialize classifier with training data\n",
    "    def train(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    # Method to predict labels of test examples using 'compute_distances' and 'predict_labels' methods.\n",
    "    def predict(self, X, k=1, num_loops=0):\n",
    "        if num_loops == 0:\n",
    "            dists = self.compute_distances(X)\n",
    "        else:\n",
    "            raise ValueError('Invalid value %d for num_loops' % num_loops)\n",
    "        return self.predict_labels(dists, k=k)\n",
    "\n",
    "    # Method to compute Euclidean distances from each text example to every training example  \n",
    "    def compute_distances(self, X):\n",
    "        num_test = X.shape[0]\n",
    "        num_train = self.X_train.shape[0]\n",
    "        dists = np.zeros((num_test, num_train))\n",
    "        # Compute distances from each test example to every training example\n",
    "        for i in range(num_test):\n",
    "            for j in range(num_train):\n",
    "                dists[i, j] = np.sqrt(np.sum((X[i] - self.X_train[j]) ** 2))\n",
    "        return dists\n",
    "\n",
    "    # Method to predict labels of test examples using chosen value of k given Euclidean distances obtained from 'compute_distances' method.\n",
    "    def predict_labels(self, dists, k=1):\n",
    "        num_test = dists.shape[0]\n",
    "        y_pred = np.zeros(num_test)\n",
    "        # Predict labels using k nearest neighbors\n",
    "        for i in range(num_test):\n",
    "            closest_y = self.y_train[np.argsort(dists[i])[:k]]\n",
    "            y_pred[i] = np.argmax(np.bincount(closest_y))\n",
    "        return y_pred\n",
    "\n",
    "def visualize_data(X_train, y_train):\n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    num_classes = len(classes)\n",
    "    samples_per_class = 7\n",
    "    for y, cls in enumerate(classes):\n",
    "        idxs = np.flatnonzero(y_train == y)\n",
    "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "        for i, idx in enumerate(idxs):\n",
    "            plt_idx = i * num_classes + y + 1\n",
    "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "            plt.imshow(X_train[idx].astype('uint8'))\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title(cls)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Download CIFAR10 data and store it in current directory if you have not done it.\n",
    "    #download_data()\n",
    "    cifar10_dir = r'D:/9th semester/git/ML_Spring_23_24/Mid/assignments/KNN-HW/cifar-10-batches-py'\n",
    "\n",
    "    # Load training and testing data from CIFAR10 dataset\n",
    "    X_train, y_train, X_test, y_test = data_utils.load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Checking the size of the training and testing data\n",
    "    print('Training data shape: ', X_train.shape)\n",
    "    print('Training labels shape: ', y_train.shape)\n",
    "    print('Test data shape: ', X_test.shape)\n",
    "    print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "    # Visualize the data if you want\n",
    "    # visualize_data(X_train, y_train)\n",
    "\n",
    "    # Memory error prevention by subsampling data. We sample 10000 training examples and 1000 test examples.\n",
    "    num_training = 10000\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "\n",
    "    num_test = 1000\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Reshape data and place into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    print(X_train.shape, X_test.shape)  # X_train should be (10000, 3072) and X_test should be (1000, 3072)\n",
    "\n",
    "    # Performing KNN\n",
    "    classifier = KNearestNeighbor()\n",
    "\n",
    "    # Train the classifier\n",
    "    classifier.train(X_train, y_train)\n",
    "\n",
    "    # Predict labels for test data\n",
    "    y_test_pred = classifier.predict(X_test, k=5)\n",
    "\n",
    "    # Compute and print the fraction of correctly predicted examples\n",
    "    num_correct = np.sum(y_test_pred == y_test)\n",
    "    accuracy = float(num_correct) / num_test\n",
    "    print('Got %d / %d correct with k=5 => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "    # Accuracy above should be ~ 29-30%\n",
    "\n",
    "    # Perform 5-fold cross validation to find optimal k from choices below\n",
    "    num_folds = 5\n",
    "    k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "\n",
    "    X_train_folds = np.array_split(X_train, num_folds)\n",
    "    y_train_folds = np.array_split(y_train, num_folds)\n",
    "    k_to_accuracies = {}  # dictionary to hold validation accuracies for each k \n",
    "\n",
    "    # Loop over the k values\n",
    "    for k in k_choices:\n",
    "        k_to_accuracies[k] = []  # each key, k, should hold its list of 5 validation accuracies\n",
    "\n",
    "        # Loop over the folds\n",
    "        for fold in tqdm(range(num_folds), desc=f'k = {k}'):\n",
    "            # Get the training and validation data for this fold\n",
    "            X_train_fold = np.concatenate([f for i, f in enumerate(X_train_folds) if i != fold])\n",
    "            y_train_fold = np.concatenate([f for i, f in enumerate(y_train_folds) if i != fold])\n",
    "            X_val_fold = X_train_folds[fold]\n",
    "            y_val_fold = y_train_folds[fold]\n",
    "\n",
    "            # Train the classifier\n",
    "            classifier.train(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Predict labels for the validation data\n",
    "            y_val_pred = classifier.predict(X_val_fold, k=k)\n",
    "\n",
    "            # Compute and store the accuracy for this fold\n",
    "            num_correct = np.sum(y_val_pred == y_val_fold)\n",
    "            accuracy = float(num_correct) / len(y_val_fold)\n",
    "            k_to_accuracies[k].append(accuracy)\n",
    "\n",
    "    print(\"Printing our 5-fold accuracies for varying values of k:\")\n",
    "    print()\n",
    "    for k in sorted(k_to_accuracies):\n",
    "        for accuracy in k_to_accuracies[k]:\n",
    "            print('k = %d, accuracy = %f' % (k, accuracy))\n",
    "    \n",
    "    for k in sorted(k_to_accuracies):\n",
    "        print('k = %d, avg. accuracy = %f' % (k, sum(k_to_accuracies[k]) / num_folds))\n",
    "    \n",
    "    for k in k_choices:\n",
    "        accuracies = k_to_accuracies[k]\n",
    "        plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "    # Plot the trend line with error bars that correspond to standard deviation\n",
    "    accuracies_mean = np.array([np.mean(v) for k, v in sorted(k_to_accuracies.items())])\n",
    "    accuracies_std = np.array([np.std(v) for k, v in sorted(k_to_accuracies.items())])\n",
    "    plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "    plt.title('Cross-validation on k')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Cross-validation accuracy')\n",
    "    plt.savefig('cross-validation_accuracy.jpg')\n",
    "\n",
    "    # Choose best value of k based on cross-validation results\n",
    "    best_k = k_choices[np.argmax(accuracies_mean)]\n",
    "\n",
    "    # Train the classifier with the full training data\n",
    "    classifier.train(X_train, y_train)\n",
    "\n",
    "    # Predict labels of test data using the best value of k\n",
    "    y_test_pred = classifier.predict(X_test, k=best_k)\n",
    "\n",
    "    # Computing and displaying the accuracy for best k found during cross-validation\n",
    "    num_correct = np.sum(y_test_pred == y_test)\n",
    "    accuracy = float(num_correct) / num_test\n",
    "    print('Got %d / %d correct on test data => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "    # Accuracy above should be ~ 57-58%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvpr",
   "language": "python",
   "name": "cvpr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
