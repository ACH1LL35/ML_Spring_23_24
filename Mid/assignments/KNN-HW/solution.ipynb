{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, r'D:\\9th semester\\git\\ML_Spring_23_24\\Mid\\assignments\\KNN-HW\\data_utils.py')  # Insert the path to the directory containing data_utils.py\n",
    "import data_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_data():\n",
    "    pass  # Since you're loading data from your local directory, no need to download\n",
    "\n",
    "# Class to initialize and apply K-nearest neighbor classifier\n",
    "class KNearestNeighbor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # Method to initialize classifier with training data\n",
    "    def train(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    # Method to predict labels of test examples using 'compute_distances' and 'predict_labels' methods.\n",
    "    def predict(self, X, k=1, num_loops=0):\n",
    "        if num_loops == 0:\n",
    "            dists = self.compute_distances(X)\n",
    "        else:\n",
    "            raise ValueError('Invalid value %d for num_loops' % num_loops)\n",
    "        return self.predict_labels(dists, k=k)\n",
    "\n",
    "    # Method to compute Euclidean distances from each text example to every training example\n",
    "    def compute_distances(self, X):\n",
    "        num_test = X.shape[0]\n",
    "        num_train = self.X_train.shape[0]\n",
    "        dists = np.zeros((num_test, num_train))\n",
    "        for i in tqdm(range(num_test), desc=\"Computing Distances\"):\n",
    "            dists[i, :] = np.linalg.norm(self.X_train - X[i, :], axis=1)\n",
    "        return dists\n",
    "\n",
    "    # Method to predict labels of test examples using chosen value of k given Euclidean distances obtained from 'compute_distances' method.\n",
    "    def predict_labels(self, dists, k=1):\n",
    "        num_test = dists.shape[0]\n",
    "        y_pred = np.zeros(num_test)\n",
    "        for i in range(num_test):\n",
    "            closest_y = []\n",
    "            indices = np.argsort(dists[i, :])\n",
    "            closest_y = self.y_train[indices[:k]]\n",
    "            y_pred[i] = np.argmax(np.bincount(closest_y))\n",
    "        return y_pred\n",
    "\n",
    "def visualize_data(X_train, y_train):\n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    num_classes = len(classes)\n",
    "    samples_per_class = 7\n",
    "    for y, cls in enumerate(classes):\n",
    "        idxs = np.flatnonzero(y_train == y)\n",
    "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "        for i, idx in enumerate(idxs):\n",
    "            plt_idx = i * num_classes + y + 1\n",
    "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "            plt.imshow(X_train[idx].astype('uint8'))\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title(cls)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Download CIFAR10 data and store it in current directory if you have not done it.\n",
    "    # download_data()\n",
    "    cifar10_dir = 'D:\\9th semester\\git\\ML_Spring_23_24\\Mid\\assignments\\KNN-HW\\cifar-10-batches-py'\n",
    "\n",
    "    # Load training and testing data from CIFAR10 dataset\n",
    "    X_train, y_train, X_test, y_test = data_utils.load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Checking the size of the training and testing data\n",
    "    print('Training data shape: ', X_train.shape)\n",
    "    print('Training labels shape: ', y_train.shape)\n",
    "    print('Test data shape: ', X_test.shape)\n",
    "    print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "    # Visualize the data if you want\n",
    "    # visualize_data(X_train, y_train)\n",
    "\n",
    "    # Memory error prevention by subsampling data. We sample 10000 training examples and 1000 test examples.\n",
    "    num_training = 10000\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "\n",
    "    num_test = 1000\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # Reshape data and place into rows. Flatten the training and test data so each row \n",
    "    # consists of all pixels of an example\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    print(X_train.shape, X_test.shape)  # X_train should be (10000, 3072) and X_test should be (1000, 3072)\n",
    "\n",
    "    # Performing KNN\n",
    "    classifier = KNearestNeighbor()\n",
    "\n",
    "    # Use the KNearestNeighbour classifier to do as follows:\n",
    "    # 1) Initialize classifier with training data\n",
    "    # 2) Use classifier to compute distances from each test example in X_test to every training example\n",
    "    # 3) Use classifier to predict labels of each test example in X_test using k=5\n",
    "    classifier.train(X_train, y_train)\n",
    "    y_test_pred = classifier.predict(X_test, k=5)\n",
    "\n",
    "    num_correct = np.sum(y_test_pred == y_test)  # number of test examples correctly predicted\n",
    "    accuracy = float(num_correct) / num_test\n",
    "    print('Got %d / %d correct with k=5 => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "    # Accuracy above should be ~ 29-30%\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
