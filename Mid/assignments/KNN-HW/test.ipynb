{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, r'D:\\9th semester\\git\\ML_Spring_23_24\\Mid\\assignments\\KNN-HW')  # Insert the path to the directory containing data_utils.py\n",
    "import data_utils\n",
    "import download\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def download_data():\n",
    "    pass\n",
    "\n",
    "# Class to initialize and apply K-nearest neighbour classifier\n",
    "class KNearestNeighbor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # Method to initialize classifier with training data\n",
    "    def train(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    # Method to predict labels of test examples using 'compute_distances' and 'predict_labels' methods.\n",
    "    def predict(self, X, k=1, distance_metric=None):\n",
    "        if distance_metric is None:\n",
    "            distance_metric = ['euclidean', 'manhattan']  # Default to using both metrics\n",
    "        elif not isinstance(distance_metric, list):\n",
    "            distance_metric = [distance_metric]  # Convert to list if a single metric is provided\n",
    "\n",
    "        y_preds = []\n",
    "\n",
    "        for metric in distance_metric:\n",
    "            if metric == 'euclidean':\n",
    "                dists = self.compute_distances(X, metric='euclidean')\n",
    "            elif metric == 'manhattan':\n",
    "                dists = self.compute_distances(X, metric='manhattan')\n",
    "            else:\n",
    "                raise ValueError('Invalid distance metric provided')\n",
    "\n",
    "            y_pred = self.predict_labels(dists, k=k)\n",
    "            y_preds.append(y_pred)\n",
    "\n",
    "        # Return a list of predictions corresponding to each distance metric\n",
    "        return y_preds\n",
    "\n",
    "    # Method to compute Euclidean distances from each text example to every training example  \n",
    "    def compute_distances(self, X, metric):\n",
    "        num_test = X.shape[0]\n",
    "        num_train = self.X_train.shape[0]\n",
    "        dists = np.zeros((num_test, num_train))\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        # Compute distances from each test example (in argument 'X' of this method) to every training example and store distances in\n",
    "        # dists variable given above. For each row, i, dist[i] should contain distances between test example i and every training example.\n",
    "        for i in range(num_test):\n",
    "            for j in range(num_train):\n",
    "                if metric == 'euclidean':\n",
    "                    dists[i, j] = np.sqrt(np.sum((X[i] - self.X_train[j]) ** 2))\n",
    "                elif metric == 'manhattan':\n",
    "                    dists[i, j] = np.sum(np.abs(X[i] - self.X_train[j]))\n",
    "                else:\n",
    "                    raise ValueError('Invalid distance metric provided')\n",
    "\n",
    "        return dists\n",
    "\n",
    "    # Method to predict labels of test examples using chosen value of k given Euclidean distances obtained from 'compute_distances' method.\n",
    "    def predict_labels(self, dists, k=1):\n",
    "        num_test = dists.shape[0]\n",
    "        y_pred = np.zeros(num_test)\n",
    "        # YOUR CODE HERE\n",
    "        # Given dists computed using 'compute_distances' method above, obtain k closest distances to training examples for each test example\n",
    "        # dists[i]. Use k closest distances obtained to predict label of each dists[i]. Label of each dists[i] should be stored in y_pred[i].\n",
    "        for i in range(num_test):\n",
    "            # Find k-nearest neighbors for each test example\n",
    "            # closest_y = []\n",
    "            closest_y = self.y_train[np.argsort(dists[i])[:k]]\n",
    "            # Predict the label which occurs most frequently\n",
    "            y_pred[i] = np.argmax(np.bincount(closest_y))\n",
    "        return y_pred\n",
    "\n",
    "def visualize_data(X_train, y_train):\n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    num_classes = len(classes)\n",
    "    samples_per_class = 7\n",
    "    for y, cls in enumerate(classes):\n",
    "        idxs = np.flatnonzero(y_train == y)\n",
    "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "        for i, idx in enumerate(idxs):\n",
    "            plt_idx = i * num_classes + y + 1\n",
    "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "            plt.imshow(X_train[idx].astype('uint8'))\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title(cls)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Download CIFAR10 data and store it in current directory if you have not done it.\n",
    "    #download_data()\n",
    "    cifar10_dir = r'D:/9th semester/git/ML_Spring_23_24/Mid/assignments/KNN-HW/cifar-10-batches-py'\n",
    "\n",
    "    # Load training and testing data from CIFAR10 dataset\n",
    "    X_train, y_train, X_test, y_test = data_utils.load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Checking the size of the training and testing data\n",
    "    print('Training data shape: ', X_train.shape)\n",
    "    print('Training labels shape: ', y_train.shape)\n",
    "    print('Test data shape: ', X_test.shape)\n",
    "    print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "    #Visualize the data if you want\n",
    "    visualize_data(X_train, y_train)\n",
    "\n",
    "    # Memory error prevention by subsampling data. We sample 10000 training examples and 1000 test examples.\n",
    "    num_training = 5000\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "\n",
    "    num_test = 500\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # Reshape data and place into rows. Flatten the training and test data so each row \n",
    "    # consists of all pixels of an example\n",
    "    \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    \n",
    "    print(X_train.shape, X_test.shape) # X_train should be (10000, 3072) and X_test should be (1000, 3072)\n",
    "\n",
    "    # Performing KNN\n",
    "    classifier = KNearestNeighbor()    \n",
    "    # YOUR CODE HERE\n",
    "    # Use the KNearestNeighbour classifier to do as follows:\n",
    "    # 1) Initialize classifier with training data\n",
    "    # 2) Use classifier to compute distances from each test example in X_test to every training example\n",
    "    # 3) Use classifier to predict labels of each test example in X_test using k=5 \n",
    "    \n",
    "    # Initialize classifier with training data\n",
    "    classifier.train(X_train, y_train)\n",
    "    y_test_pred = classifier.predict(X_test, k=5, distance_metric=['euclidean', 'manhattan'])\n",
    "    for metric, y_pred in zip(['euclidean', 'manhattan'], y_test_pred):\n",
    "        num_correct = np.sum(y_pred == y_test)  # number of test examples correctly predicted, where y_test_pred\n",
    "                                                # should contain labels predicted by classifier\n",
    "        accuracy = float(num_correct) / num_test            \n",
    "        print()\n",
    "        print('Got %d / %d correct with k=5 => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "        print()\n",
    "        # Accuracy above should be ~ 29-30%\n",
    "\n",
    "    # Perform 5-fold cross validation to find optimal k from choices below\n",
    "    num_folds = 5\n",
    "    k_choices = [1, 3, 5, 8, 10]\n",
    "\n",
    "    X_train_folds = []\n",
    "    y_train_folds = []\n",
    "    # Training data is split into 5 folds\n",
    "    X_train_folds = np.array_split(X_train,num_folds)\n",
    "    y_train_folds = np.array_split(y_train,num_folds)\n",
    "    k_to_accuracies = {} # dictionary to hold validation accuracies for each k \n",
    "\n",
    "    for distance_metric in ['euclidean', 'manhattan']:\n",
    "        print()\n",
    "        print(f\"Evaluating using {distance_metric} distance metric:\")\n",
    "        print()\n",
    "\n",
    "        for k in k_choices:\n",
    "            k_to_accuracies[k] = [] # each key, k, should hold its list of 5 validation accuracies\n",
    "            \n",
    "            # For each fold of cross validation\n",
    "            for num_knn in range(0,num_folds):\n",
    "                # YOUR CODE HERE\n",
    "                # 1) Split training data into validation fold and training folds\n",
    "                # 2) Inititialize classifier with training folds and compute distances between \n",
    "                #    examples in validation fold and training folds\n",
    "                # 3) Use classifier to predict labels of valdation fold for given k value\n",
    "                \n",
    "                # Split training data into validation fold and training folds\n",
    "                X_val_fold = X_train_folds[num_knn]\n",
    "                y_val_fold = y_train_folds[num_knn]\n",
    "\n",
    "                X_train_fold = np.concatenate([X_train_folds[i] for i in range(num_folds) if i != num_knn])\n",
    "                y_train_fold = np.concatenate([y_train_folds[i] for i in range(num_folds) if i != num_knn])\n",
    "\n",
    "                # Initialize classifier with training folds and compute distances between examples in validation fold and training folds\n",
    "                classifier.train(X_train_fold, y_train_fold)\n",
    "                dists_fold = classifier.compute_distances(X_val_fold, metric=distance_metric)\n",
    "\n",
    "                # Use classifier to predict labels of validation fold for given k value\n",
    "                y_val_pred = classifier.predict_labels(dists_fold, k=k)\n",
    "                \n",
    "                # number of test examples correctly predicted, where y_test_pred contains labels\n",
    "                # predicted by classifier on validation fold\n",
    "                num_correct = np.sum(y_val_pred == y_val_fold) \n",
    "                accuracy = float(num_correct) / X_val_fold.shape[0]  # Use the number of validation examples for accuracy calculation\n",
    "                k_to_accuracies[k].append(accuracy)                \n",
    "                print('Got %d / %d correct => accuracy: %f' % (num_correct, X_val_fold.shape[0], accuracy))\n",
    "\n",
    "\n",
    "        print()\n",
    "        print(\"Printing our 5-fold accuracies for varying values of k:\")\n",
    "        print()\n",
    "        for k in sorted(k_to_accuracies):\n",
    "            for accuracy in k_to_accuracies[k]:\n",
    "                print('k = %d, accuracy = %f' % (k, accuracy))\n",
    "        \n",
    "        for k in sorted(k_to_accuracies):\n",
    "            print('k = %d, avg. accuracy = %f' % (k, sum(k_to_accuracies[k])/5))\n",
    "        \n",
    "        for k in k_choices:\n",
    "            accuracies = k_to_accuracies[k]\n",
    "            plt.scatter([k] * len(accuracies), accuracies)\n",
    "        plt.show()\n",
    "\n",
    "        # plot the trend line with error bars that correspond to standard deviation\n",
    "\n",
    "        accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "        accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "        plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "        plt.title('Cross-validation on k')\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('Cross-validation accuracy')\n",
    "        # plt.savefig('cross-validation_accuracy.jpg')\n",
    "        if distance_metric == 'euclidean':\n",
    "            plt.savefig('cross-validation_accuracy_euclidean.jpg')\n",
    "        else:\n",
    "            plt.savefig('cross-validation_accuracy_manhattan.jpg')\n",
    "        plt.show()\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        # Choose best value of k based on cross-validation results\n",
    "        # Intialize classifier and predict labels of test data, X_test, using best value of k\n",
    "        \n",
    "        best_k = k_choices[np.argmax(accuracies_mean)]\n",
    "        print()\n",
    "        print(\"Best value of k:\", best_k)\n",
    "        print()\n",
    "\n",
    "        # Initialize classifier and predict labels of test data, X_test, using best value of k\n",
    "        classifier = KNearestNeighbor()\n",
    "        classifier.train(X_train, y_train)\n",
    "        y_test_pred = classifier.predict(X_test, k=best_k)\n",
    "\n",
    "        # Computing and displaying the accuracy for best k found during cross-validation\n",
    "        num_correct = np.sum(y_test_pred == y_test)\n",
    "        accuracy = float(num_correct) / num_test\n",
    "        print('Got %d / %d correct on test data => accuracy: %f' % (num_correct, num_test, accuracy))        \n",
    "        # Accuracy above should be ~ 57-58%     \n",
    "        \n",
    "    # Comparison between Euclidean and Manhattan distances\n",
    "    euclidean_accuracy = accuracy_score(y_test, y_test_pred[0])\n",
    "    manhattan_accuracy = accuracy_score(y_test, y_test_pred[1])\n",
    "\n",
    "    print()\n",
    "    print(\"Euclidean Accuracy: \", euclidean_accuracy)\n",
    "    print(\"Manhattan Accuracy: \", manhattan_accuracy)\n",
    "    print()\n",
    "    \n",
    "    if euclidean_accuracy > manhattan_accuracy:\n",
    "        print('Euclidean distance performed better.')\n",
    "    elif euclidean_accuracy < manhattan_accuracy:\n",
    "        print('Manhattan distance performed better.')\n",
    "    else:\n",
    "        print('Both distance metrics performed equally.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
